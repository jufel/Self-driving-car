{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLKENh9lKe53"
   },
   "outputs": [],
   "source": [
    "# IMPORT ALL NECESSARY LIBRARIES\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, Dense, BatchNormalization, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split \n",
    "path = r\"D:\\Uon_acads\\Sem_2\\MLiS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "Cl0lbtg6GsU5",
    "outputId": "06b4f110-1110-4101-e30a-69bb1ffa1f94"
   },
   "outputs": [],
   "source": [
    "# CHECK IF TENSORFLOW DETECTS THE GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING SOME OF THE HYPER PARAMETERS\n",
    "bs = 128 # batch size\n",
    "img_width = 224 # input img size\n",
    "img_height = img_width\n",
    "val_spilt = 0.2 # fraction of training data used for validation\n",
    "lr = 1e-3 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO READ AN IMAGE GIVEN ITS FILE PATH\n",
    "def read_dataset(img_path,label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img,[img_width,img_height])\n",
    "    return img,label\n",
    "\n",
    "#FUNCTION TO ADD NOISE TO THE INPUT IMAGE\n",
    "def add_noise(img):\n",
    "    noise = tf.random.normal(tf.shape(img),0,5)\n",
    "    img += noise\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path +\"\\\\\" + r'training_norm_added.csv')\n",
    "img_path = []\n",
    "angle = []\n",
    "speed = []\n",
    "for _,row in df.iterrows():\n",
    "    img_path.append(path + \"\\\\\" + r'training_data_added\\training_data' + \"\\\\\" + str(int(row[\"image_id\"])) + r'.png')\n",
    "    angle.append(row[\"angle\"])\n",
    "    speed.append(int(row[\"speed\"]))\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "train_im, valid_im, train_lab, valid_lab = train_test_split(img_path, speed, test_size=0.20,\n",
    "                                                            random_state=40, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA - READING AND AUGMENTATION\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_im, {'angle':train_lab}))\n",
    "ds_train = ds_train.map(read_dataset).cache().map(lambda image, label: (tf.image.random_contrast(image, lower = 0.9, upper = 1.1), label)\n",
    "                                                                ).map(lambda image, label: (tf.image.random_saturation(image, lower = 0.9, upper = 1.1),label)\n",
    "                                                                     ).map(lambda image, label: (tf.image.random_brightness(image, 0.7 ,1.3),label)\n",
    "                                                                          ).map(lambda image, label: (add_noise(image), label)\n",
    "                                                                               ).shuffle(1000).batch(128).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCHING VALIDATION DATA\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((valid_im, {'angle':valid_lab}))\n",
    "ds_valid = ds_valid.map(read_dataset).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING MODEL LOSSES AND METRICS\n",
    "losses = {\"angle\": \"mse\"}\n",
    "lossWeights = {\"angle\": 1.0}\n",
    "metrics = {\"angle\": \"mean_squared_error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVrv-lwAjOmh",
    "outputId": "5c84502e-0547-4a70-c063-b9ad600e3dea"
   },
   "outputs": [],
   "source": [
    "#BUILDING AN EXTRA FEW DIFFERENT LAYERS JOINING THE LAST 10TH LAYER\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy (devices=[\"/gpu:0\",\"/cpu:0\"]) # parallel computing\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    mobile = tf.keras.applications.MobileNetV3Large(input_shape=[img_width,img_height,3]) # Use MobileNetV3-Large as base model\n",
    "    \n",
    "    x = mobile.layers[-10].output\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Conv2D(2,(1,1),strides = (1, 1),kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    angle1 = Dense(64, activation='relu', name='angle_hidden')(x)\n",
    "\n",
    "    angle_pred = Dense(1, activation = 'relu', name='angle')(angle1)\n",
    "\n",
    "    model = Model(inputs = mobile.input, outputs = [angle_pred])\n",
    "    \n",
    "    for layer in model.layers[:-44]: #14,24,37,54\n",
    "      layer.trainable = False # fALSE\n",
    "    \n",
    "    #COMPILE THE NEW MODEL\n",
    "    model.compile(optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics = metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hObdYIdA6hcw",
    "outputId": "4afd64dc-1d9a-44cc-a848-ced7a07967af"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqO6i05kTgMA"
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"training_angle_only/cp.ckpt\"\n",
    "checkpoint_path = os.path.join(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\",checkpoint_name)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLOo1YHSCInm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.fit(ds_train, epochs=10, validation_data=ds_valid, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTvB1CTzDng1",
    "outputId": "fb6a7954-6888-451a-9bed-d82dfcd3a15d"
   },
   "outputs": [],
   "source": [
    "# SAVE THE MODEL\n",
    "model.save(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\")\n",
    "model.save(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\\my_model_angle.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2mkDH6khh_c"
   },
   "outputs": [],
   "source": [
    "# LOAD THE speed MODEL (here we are loading the speed model so that we have both speed and angle models \n",
    "#                                                   loaded to make predictions of speed and angle)\n",
    "new_model = tf.keras.models.load_model(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_speed\\my_model_speed.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO READ TESTING DATA\n",
    "def read_dataset_test(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img,[224,224])\n",
    "    img = tf.reshape(img,[1,224,224,3])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO CREATE PREDICTIONS OF THE TEST DATA\n",
    "predictions = []\n",
    "angle_pred = []\n",
    "speed_pred = []\n",
    "for i in range(1,1021):\n",
    "    angle_pred.append(new_model.predict(read_dataset_test(path + \"\\\\\" + r'test_data\\test_data' + \"\\\\\" + str(i) + r'.png')))\n",
    "    speed_pred.append(model.predict(read_dataset_test(path + \"\\\\\" + r'test_data\\test_data' + \"\\\\\" + str(i) + r'.png')))\n",
    "    \n",
    "for i in range(len(angle_pred)):\n",
    "    speed = speed_pred[i]\n",
    "    if abs(1-speed) < abs(speed-0):\n",
    "        speed = 1\n",
    "    else:\n",
    "        speed = 0\n",
    "    predictions.append([round(angle_pred[i][0][0],4),speed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE PREDICTIONS IN A .CSV FILE\n",
    "df1 = pd.DataFrame(predictions,index = np.arange(len(predictions))+1, columns=['angle', 'speed'])\n",
    "df1.to_csv(path +\"\\\\\" + 'multi_model_output.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Actual_mobilenetv3_large.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
